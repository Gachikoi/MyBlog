# 硬件结构
## CPU与内存
- 计算机数据存储中，存储数据的基本单位是字节，每个字节都对应一个内存地址。
- 32位cpu（32位位宽）可以一次运算4个字节，64位一次8个。
- 总线：地址总线、数据总线、控制总线。
- cpu的位宽最好不要小于线路位宽，否则工作起来会非常复杂。所以32位cpu最好和32位宽的线路搭配。
- 32位地址总线可以表示2^32=4G的地址空间。所以32位cpu最多支持4G内存。
## CPU缓存
- CPU每个核心都有L1、L2缓存，所有CPU公用一个L3缓存。
- CPU Cache是由很多个Cache Line组成的，也就是说，CPU缓存从内存中读取数据是一块一块数据读取的，而非按照单个元素来读取。
- CPU从L1中读取数据可以零碎地读取。
- 比如L1一次读取了64字节的数据，对于int32的数组来说，一次读取16个数组元素。我们访问这16个元素就非常快。
- L1中，数据缓存和指令缓存是分别存储的。
- 对于一个无序数组，我们对他排序再让其中小于50的数变0，比先变0再排序快。因为除了数据缓存，我们还有指令缓存。排序后，“将小于50的数变0”这条指令的缓存命中率大大提高了。否则，我们可能需要一直交换缓存，将这条指令换入换出L1。
- 对于多核CPU，当一个线程在不同的核心来回切换时，各个核心的缓存命中率就会受到影响。当有多个同时执行「计算密集型」的线程时，我们可以把线程绑定在某一个 CPU 核心上。
## 缓存一致性
对于多核CPU，因为L1、L2不共享，所以我们需要保证数据修改的一致性。
- 什么时机将Cache中的数据写回到内存？写直达（直接写入内存+缓存）、写回（写入缓存，缓存再写入内存）。
- 但这并不能保证数据修改的一致性，所以需要基于总线嗅探机制的MESI协议。
## 伪共享
数据是一块一块地写入缓存的，所以当两个数据在同一块中，而两个CPU又要分别修改这两个数据时，就会出现伪共享的情况。

因为需要保证缓存一致性，而缓存一致性实现的基本单位是“一块”数据，因此每次修改A数据时，cpu2不能修改B数据；cpu2想要修改B数据，要等cpu1将A写回到内存中。这时，缓存就不起作用了。


如何解决？以空间换取时间！

假设缓存一次读取一块数据的大小是八个int32，A、B都是一个int32，则在A后填充7个长度为4字节的数据，使B在另一个数据块中，这样A、B的读写就互不干扰了。
## 软中断
发生中断时，CPU会停下当前任务去处理中断事件。在此期间，cpu可能会临时关闭中断响应机制。如果中断时间过长，有的中断可能不会被处理，也会对正常的进程调度产生影响。所以Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。

- 上半部用来快速处理中断，一般会暂时关闭中断请求，直接处理硬件请求，也就是硬中断。
- 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行，由内核触发，也就说软中断。
## 浮点数的存储
规格化。浮点数=符号位+指数位+尾数。

由于不是所有数比如说十进制0.1都能化为有限的二进制数，所以这些数需要估算，导致了浮点数计算不精确。比如0.1+0.2 ！= 0.3

# 内存管理
## 内存映射
为了建立虚拟内存和物理内存的关联，我们需要用分段/分页的方式来建立内存映射。

### 分段
以一个进程为基本分段，分配给一个进程连续的物理地址空间。所以有多少个进程就有多少个段表项，段表所占空间很小。

使用段表，查询虚拟地址对应的物理地址。

但是会产生外部内存碎片和内存交换效率低的问题（一旦需要腾出空间，整个程序都要进行swap）。

### 分页
在分页的方式中，虚拟内存叫做页page，物理内存叫做页帧frame。

将内存分为大小固定的页，虚拟和物理中的页大小是一样的，页号数量可以不一样。

以页为基本分段，页表项的数量非常庞大，因此我们需要采用多级页表来减少内存的使用。

#### 有关多级页表
你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？

但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。因此大大节省了空间。

## TLB
为了防止频繁查找页表，根据局部性原理，我们在cpu内部存储缓存TLB，用于快速查找页表项。


## 虚拟内存
虚拟内存有什么作用？

- 第一，虚拟内存可以使得进程的运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

## 在4GB物理内存的机器上申请8G内存
由于申请的是虚拟内存，不访问就不会分配物理内存空间，所以申请到8G内存是可能的。
### 32位系统下
在linux中，虚拟内存为1G内核空间&3G用户空间，申请会直接失败。
### 64位系统下
在linux中，虚拟内存位128T内核空间&128T用户空间，申请成功，最大可申请（128T-进程自己所占虚拟空间）的空间。但是申请是否成功也和linux中的overcommit_memory参数有关。

但是，申请虚拟内存的过程也是用到了物理内存的，因此即使没有访问虚拟内存空间也可能因为out of memory进程被kill掉。

如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制：

- 如果没有开启 Swap 机制，程序就会直接 OOM；
- 如果有开启 Swap 机制，程序可以正常运行。

# 进程、线程基础知识
进程等待事件完成时进入阻塞状态，但是阻塞状态的进程并不一定会被换出到硬盘上。
## 进程与线程
线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。

当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；  
当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

## 一个进程最多可以创建多少个线程？
这个问题和进程的虚拟空间内存上限、系统参数限制有关。

当然，创建线程也会有系统开销，即消耗物理内存。

## 线程崩溃了，进程也会崩溃吗？
一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，各个线程的地址空间是共享的，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃。

但是，进程可以自定义对操作系统发出的kill信号的处理方式，即执行相应的信号处理程序（函数）。这时进程就可以根据具体情况来平滑退出，或者选择忽略信号。但是有种kill信号无论如何都会让进程立即退出。

## 线程的实现
### 用户线程
用户线程是基于用户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。

所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。

用户级线程的模型，即多个用户线程对应同一个内核线程。
 
1. 用户线程的优点：

每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；
用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；

2. 用户线程的缺点：

由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。
当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。
由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢。

### 内核线程

内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。

内核线程的模型，即一个用户线程对应一个内核线程，

1. 内核线程的优点：

在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；
分配给线程，多线程的进程获得更多的 CPU 运行时间；

2. 内核线程的缺点：

在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；
线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大。

### LWP
![LWP原理示意图](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/22-LWP.jpg)
轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。

3. M : N 模式

根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。

优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。

4. 组合模式

如上图的进程 5，此进程结合 1:1 模型和 M:N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。

### 多对多模型
多对多模型多路复用多个用户级线程到同样数量或更少数量的内核线程。内核线程的数量可能与特定应用程序或特定机器有关（应用程序在多处理器上比在单处理器上可能分配到更多数量的线程）。

现在我们考虑一下这些设计对并发性的影响。虽然多对一模型允许开发人员创建任意多的用户线程，但是由于内核只能一次调度一个线程，所以并未增加并发性。虽然一对一模型提供了更大的并发性，但是开发人员应小心，不要在应用程序内创建太多线程（有时系统可能会限制创建线程的数量）。

多对多模型没有这两个缺点：开发人员可以创建任意多的用户线程，并且相应内核线程能在多处理器系统上并发执行。而且，当一个线程执行阻塞系统调用时，内核可以调度另一个线程来执行。

多对多模型的一种变种仍然多路复用多个用户级线程到同样数量或更少数量的内核线程，但也允许绑定某个用户线程到一个内核线程。这个变种，有时称为双层模型。  
![多对多模型](https://img-blog.csdnimg.cn/img_convert/57225b90ee7017da6977c56bb44316d8.png)

## 调度算法
1. 先来先服务（First Come First Serve, FCFS）
2. 最短作业优先（Shortest Job First, SJF）
3. 高响应比优先 （Highest Response Ratio Next, HRRN）  
![高相应比优先调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg)  
理想算法，不可实现。
4. 时间片轮转（Round Robin, RR）/ 轮询
5. 最高优先级（Highest Priority First，HPF）调度，低优先级的进程可能会出现饥饿现象
6. 多级反馈队列（Multilevel Feedback Queue）调度算法

![多级反馈队列调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg)

- 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；

- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；

- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行.

# 进程通信
## 管道
所谓的管道就是内核里的一串缓存。进程通过写入读出这串缓存来实现进程间的通信。

管道这种通信方式效率低，不适合进程间频繁地交换数据。

管道传输的数据是无格式的流且大小受限。

匿名管道的生命周期随进程创建而建立，随进程结束而销毁。

通信方法：
1. 使用匿名管道。但由于管道没有实体，只能通过fork来复制fd文件描述符，因此通信范围限制在父子进程之间。

    父进程创建管道，获得管道描述符fd[0]、fd[1]，前者为读端，后者为写端。

    父进程fork子进程，子进程也获得这两个管道描述符，于是两个进程即可通信。

    为防止混乱，我们要分别关闭一个读端和一个写端，所以一个管道只能实现单向通信；想要双向通信则需要创建两个管道。

2. 使用命名管道。提前创建好了管道文件，只要使用这个文件的进程都可以相互通信。

## 消息队列
消息队列是保存在内核中的消息链表，在发送数据时，会分成一个个消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块。

消息队列的生命周期随内核，除非主动释放消息队列。

内核中每个消息体都有最大长度的限制，队列中消息体总长度也有限制，所以消息队列不适合大数据传输。

消息队列通信过程中存在用户态和内核态之间的数据拷贝开销。当然管道同理。因为都是通过内核来存储通信数据的。

## 共享内存
共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。

## 信号量
为防止同时访问共享内存冲突，我们需要信号量来实现保护机制。

信号量的两种原子操作：
1. P操作：将信号量-1。若减后信号量<0，则表明资源已被占用，进程需要阻塞等待；信号量 >= 0，进程可正常继续执行。
2. V操作：将信号量+1。若加后信号量<=0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；信号量 > 0，则表明当前没有阻塞中的进程。

P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

信号初始化为 `1`，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。

可以发现，信号初始化为 `0`，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。

## 信号
信号是进程间通信机制中唯一的异步通信机制。可以操控进程，当然进程也可以选择是否接受信号。

## Socket
可以实现本地及远程主机通信。

# 多线程冲突
## 锁
1. 自旋锁：当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」。

    在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

2. 无等待锁。当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。
## 信号量
PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。

## 经典问题
### 生产者消费者问题
同时实现同步和互斥。缓存中必须先有物品，消费者才能拿走物品；生产者不能和消费者同时操作缓存。

### 哲学家就餐问题

1. 可以让编号为奇数的哲学家先拿左侧叉子，后拿右侧叉子；偶数先拿右侧叉子，后拿左侧叉子。每个叉子一个信号量，初值为1。

![哲学家问题解法1](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/28-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%B8%89%E7%A4%BA%E4%BE%8B.jpg)

2. 使用了一个信号量数组，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。

![哲学家问题解法2](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/30-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E5%9B%9B%E7%A4%BA%E4%BE%8B.jpg)

### 读者-写者问题
1. 读者优先。写者可能饥饿。

2. 写者优先。读者可能饥饿。

3. 公平策略。

# 死锁
死锁只有同时满足以下四个条件才会发生：

- 互斥条件；
- 持有并等待条件；
- 不可剥夺条件；
- 环路等待条件；两个线程获取资源的顺序构成了环形链。
## 死锁避免
1. 银行家算法。开销很大，很少在操作系统中使用。
![银行家算法](https://img2018.cnblogs.com/i-beta/1358881/201911/1358881-20191125171934215-167814328.png)

2. 资源有序分配法。常用。当线程A和线程B会申请同一资源时，线程A和线程B获取的资源的顺序要一样。这样就打破了环路等待条件。

# 锁
1. 互斥锁。互斥锁加锁失败后，线程会释放 CPU ，给其他线程。

对于执行时间短的任务，互斥锁产生的上下文切换时间可能比执行时间还要长，这时应该使用自旋锁。

2. 自旋锁。自旋锁加锁失败后，线程会忙等待，直到它拿到锁。

上述两种都是最基本的锁，高等级的锁都是基于他们实现的。

3. 读写锁。

    公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。

4. 悲观锁。前面3种都是悲观锁，对于共享数据操作前，我们要先加锁。

5. 乐观锁，也叫无锁编程。先修改数据，再验证这段时间内有没有修改冲突，如果没有就修改资源；如果有就放弃本次操作。

    只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。

# 内存页面置换算法
## 缺页异常（缺页中断）
它与一般中断的主要区别在于：

- 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。

- 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。

## 常用页面置换算法
1. 最佳页面置换算法（OPT） 
    
    置换在【未来】最长时间不访问的页面。

    不可能实现。

2. 先进先出置换算法（FIFO）  

3. 最近最久未使用的置换算法（LRU） 

    选择最长时间没有被访问的页面。

    需要维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。因为开销很大，所以很少应用。

4. 时钟页面置换算法（Lock）。与LRU近似，又是对FIFO的改进。

    把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

    当发生缺页中断时，算法首先检查表针指向的页面：

    如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；  

    如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止。


5. 最不常用置换算法（LFU）  

    当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。

    但是需要硬件增加计数器，而且仍然要维护一个链表。

    某个页面某一时间内频繁访问，之后再也不访问了的话，这个页面难以被换出。当然可以采取定期减少访问次数的方式解决这一问题。

# 磁盘调度算法
（针对机械硬盘寻道问题）
## 先来先服务FCFS
寻道时间长。

## 最短寻道时间优先（Shortest Seek First,SSF）

会造成饥饿。

## 扫描算法（Scan）
磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。

但是每个磁道的响应频率存在差异：处在中间部分的磁道，每次路过他们的时间间隔是相近的；处在边缘部分的磁道，会连续两次路过，然后很长的一段时间内，边缘部分磁道的请求都不会被处理。

## 循环扫描算法（Circular Scan, CSCAN）

只有磁头朝某个特定方向移动时，才处理磁道访问请求。返回时直接复位磁头，这个过程很快，所以不用担心性能，并且返回中途不处理任何请求。

这样就解决了每个磁道的响应频率差异问题。

## LOOK与C-LOOK算法
LOOK是对Scan的改进，C-LOOK是对CSCAN的改进。

优化的思路时：磁头移动到【最远的请求】位置，然后立即反向移动。

# 文件
## 文件构成
1. 文件头。存储文件属性（名称、类型、位置、大小、保护、创建者、创建时间、最近修改时间...
2. 文件数据。存储文件内容。

## 文件管理
### 对于每个进程
内核跟踪每个进程打开的文件。

- 操作系统为每个进程维护一个打开文件表
- 一个打开文件描述符是这个表中的索引，方便进程对于打开文件表的查找

### 对于整个系统
需要一些数据来管理打开文件：
- 文件指针：指向最近一次读写位置。
- 文件打开计数：类似ARC，用于是否抹除内存中的文件。
- 文件磁盘位置：用于向磁盘内读写。
- 访问权限

## 文件读写
用户以字节的形式进行文件读写，而操作系统是按照扇区/数据块进行读写。然后操作系统再将用户需要的字节从块中读取。

文件系统的基本操作单位是数据块。

## 文件访问方式
1. 顺序访问

2. 随机访问

3. 基于内容访问（将内容进行哈希转换/数据库）

## 目录
目录是一类特殊的文件，存储文件/目录。

## 硬链接与软链接
硬链接相当于对文件的引用，以文件副本的形式存在，大小与源文件相同，但并不占据实际存储空间；软链接本身是一个单独的文件，文件内存储一个链接，指向源文件，软链接的大小很小。

软链接可以对不存在的目录和文件创建链接，而硬链接则不行。

[一图详解硬链接和软连接(linux)](https://www.zhihu.com/tardis/zm/art/619264530?source_id=1005)

## 虚拟文件系统
上为用户程序提供统一API，方便用户对于文件的管理。

下对各种物理文件系统进行抽象，管理系统中各种不同的文件系统。

## 文件分配
### 连续分配
文件头指定起始块和长度。

    优势：文件读取快，高效的顺序和随机访问。

    劣势：空间碎片，文件增长问题。
### 链式分配
1. 隐式链表：文件头包含第一个数据块和最后一个数据块的位置，并且每个数据块留出一个指针空间，用来存放下一个数据块的位置。

    优点：可以动态扩充，没有碎片

    缺点：难以实现随机访问;稳定性价差，若链表中指针丢失，会导致数据损坏。

2. 显式链表：把链接文件各数据块的指针显式地存放在内存的一张链接表（文件分配表FAT）中。文件头记录文件的起始块号，FAT记录每个块对应下一块的指针。

    优点：显著提高检索速度，大大减少访问磁盘的次数。

    缺点：占用内存空间，不适用于大磁盘。

### 索引
为每个文件创建一个【索引数据块】，文件头包含指向【索引数据块】的指针。

    优点：文件的创建增缩很方便，没有碎片问题，支持顺序读写和随机读写。

但是很多时候一块索引数据块放不下全部的索引信息，这是可以用【链式索引块】/【多级索引块】来存放多个索引块

## 空闲空间管理
### 空闲表法
仅有少量的空闲区时才有较好的效果，适合建立连续文件。如果有大量小的空闲区，空闲表会变得很大，查询效率很低。
![空闲表法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A9%BA%E9%97%B2%E8%A1%A8%E6%B3%95.png)
### 空闲链表法
![空闲链表法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A9%BA%E9%97%B2%E5%9D%97%E9%93%BE%E8%A1%A8.png)  
缺点同空闲表法，而且不能随机访问。
### 位图
- 1111111111111100000000010100001110
- 1表示已分配
- 位图的访问和更新要及时，否则可能会数据不一致。
- 可以先在硬盘上设置bit[i]=1，再分配block，再将内存中bit[i]=1。这样就不会出现数据丢失的情况，但是会出现磁盘空间误占的情况。

## 文件I/O
缓冲都是为了等待一堆数据准备好后，再由CPU调度进行读取，否则频繁的中断将频繁进行系统调用，CPU为处理中断多次上下文切换，大大降低CPU的效率。

### 缓冲与非缓冲I/O
- 缓冲 I/O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。

- 非缓冲 I/O，直接通过系统调用访问文件，不经过标准库缓存。

### 直接与非直接 I/O
- 直接 I/O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。

- 非直接 I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。

### 阻塞与非阻塞 I/O VS 同步与异步 I/O
先来看看阻塞 I/O，当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。

注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。过程如下图：

![阻塞I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%98%BB%E5%A1%9E%20I_O.png) 

知道了阻塞 I/O ，来看看非阻塞 I/O，非阻塞的 read 请求在数据未准备好的情况下立即返回，`可以继续往下执行`(可以执行除轮询外的其他代码，因此称之为非阻塞)，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。过程如下图：

![非阻塞I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20.png) 

注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。

为了解决这种傻乎乎轮询方式，于是 I/O 多路复用技术就出来了，如 select、poll，它是通过 I/O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。

下图是使用 select I/O 多路复用过程。注意，read 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个同步的过程，需要等待：


![非阻塞I/O多路复用](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%9F%BA%E4%BA%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png)  

实际上，无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。

而真正的异步 I/O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。

![异步I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%BC%82%E6%AD%A5%20I_O.png)  

## 进程写文件（使用缓冲 IO）过程中，写一半的时候，进程发生了崩溃，已写入的数据会丢失吗？
不会。因为进程实际上将数据写入内核缓存中，内核会寻找一个合适的时机将数据写入磁盘。即使进程崩溃，数据还在。

我们也可以在程序中调用fsync函数，在写文件时立即将数据持久化到磁盘，以解决系统崩溃导致的文件数据丢失问题。

# 设备管理
## 设备控制器
我们的电脑可以接非常多的输入输出设备，为了屏蔽设备之间的差异，每个设备都有一个“设备控制器”。

设备控制器里有芯片，可以执行自己的逻辑，也有自己的寄存器，用来与CPU进行通信。

控制器有三类寄存器：状态寄存器、命令寄存器、数据寄存器。通过写入/读取这些寄存器，操作系统可以命令设备/了解设备状态。

输入输出设备可以分为两大类：块设备和字符设备。

- 块设备，把数据存储在固定大小的块中，每个块有自己的地址，硬盘、USB是常见的块设备。

- 字符设备，以字符为单位发送或接收一个字符流，字符设备不可寻址，也没有任何寻道操作，鼠标是常见的字符设备。不可寻址和寻道指的是设备控制器对于设备，而非CPU对于设备寄存器映射到内存中的地址。

块设备通常传输的数据量会非常大，于是会有缓冲区。当缓冲区的数据囤够一部分后，再发送到设备/拷贝到内存，以减少对设备的频繁操作。

 CPU 是如何与设备的控制寄存器和数据缓冲区进行通信的？存在两个方法：

- 端口 I/O，每个控制寄存器被分配一个 I/O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 in/out 类似的指令。

- 内存映射 I/O，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区。

## I/O控制方式
1. 轮询等待  

    CPU一直查设备控制器寄存器的状态，直到输入/输出操作完成，会占用CPU全部时间。

2. 中断  

    软中断：调用代码指令  

    硬件中断：硬件通过中断控制器触发

### DMA
然而寄存器大小有限，频繁中断读取寄存器数据会让CPU效率大大降低，所以需要使用DMA(Direct Memory Access)功能。
![DMA](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/DMA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png)

## 设备驱动程序
设备驱动程序属于操作系统的一部分，提供统一接口给操作系统，屏蔽设备控制器的差异。

### 中断处理程序
设备完成了事情，则会发送中断来通知操作系统。那操作系统就需要有一个地方来处理这个中断，这个地方也就是在设备驱动程序里，它会及时响应控制器发来的中断请求，并根据这个中断的类型调用响应的`中断处理程序`进行处理。

通常，设备驱动程序初始化的时候，要先注册一个该设备的中断处理函数。

## 键盘敲入字母时，期间发生了什么？
我们先来看看 CPU 的硬件架构图：

![CPU硬件架构图](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/CPU%20%E7%A1%AC%E4%BB%B6%E6%80%BB%E7%BA%BF%E5%9B%BE.png)

CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I/O 桥接器，这个 I/O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I/O 总线，用来连接 I/O 设备，比如键盘、显示器等。

当从键盘输入时，键盘控制器向CPU发送中断请求。

CPU收到中断请求后，操作系统保存CPU上下文，然后调用键盘驱动程序的中断处理程序。

得到键盘输入的字符后，会把其放入【读缓冲区队列】，然后显示设备的驱动程序会定时从【读缓冲区队列】读取数据到【写缓冲区队列】，最后把【写缓冲区队列】的数据一个个写入到显示设备的控制器的寄存器的数据缓冲区，最后讲这些数据显示在屏幕上。

### 读缓冲队列&写缓冲队列
他们是位于计算机内存中的数据结构，用于临时存放输入输出数据。

他们通常由操作系统内核维护，但取决于具体操作系统的设计和实现方式，也可以在用户空间中实现（而不是由内核维护的内核空间）。