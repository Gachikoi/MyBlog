<!-- # TCP
## TCP Keepalive和HTTP Keep-Alive
- TCP中会由操作系统内核维护一个保活定时器。当通信双方在定时器内没有进行通信后，会向对方主机发送探测报文，以检测对方主机是否存活。这里需要注意的是，当对方主机的某个进程崩溃时，会发送FIN报文，以结束TCP连接；但是当主机宕机时，则不会发送FIN报文，这时就需要主动发起探测报文来检测对方主机是否存活
- 当建立好主机之间的TCP通信后，就可以进行HTTP报文的传送。而HTTP1.0完成一个HTTP请求后就断开TCP连接（HTTP短连接）。如果需要在一次TCP连接内交换多次HTTP报文，则需要在请求的报头中添加：
```shell
Connection: Keep-Alivess
```
来实现HTTP长连接，即HTTP的`Keep-Alive`功能
- 在HTTP1.1开始默认开启Keep-Alive功能

# 计算机网络的性能指标
- 数据传送速率=min(主机接口速率，线路带宽，交换机或路由器的接口速率)
- 设分组数为m，路由器数为n，在不考虑排队时延和处理实验的情况下，假设各分组、链路等长，主机和路由器发送速率相等。源主机通过n个路由器转发m个分组给目的主机的计算公式：(m+n)*发送时延+(n+1)*传播时延。

# 信道
- 一个码元就是一次脉冲信号。1个码元只携带1比特的信息量时，波特率（码元/秒）与比特率（比特/秒）在数值上是相等的。携带n bit则n*波特率=比特率。 --> 
# HTTP基础
## HTTP是什么
HTTP：超文本传输协议，也就是HyperText Transfer Protocol

「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。

## 状态码
1xx 提示信息。

2xx 服务器成功处理客户端请求。

3xx 客户端请求的资源发生了变动，需要客户端用新的URL重新发送请求资源，也就是重定向。

4xx 客户端发送的报文有误，服务器无法处理，也就是错误码的含义。

5xx 客户端报文正确，但服务器处理时内部发生错误，属于服务端的错误码。

## 常见字段
### Host
客户端发送请求时，用来指定服务器的域名。

### Content-Length
服务器返回数据时用来表明本次回应的数据长度。

### Connection
常用于客户端要求服务器使用【HTTP长连接】，设为【Keep-Alive】。

### Content-Type
服务器用来告诉客户端本次数据是什么格式。

### Accept
客户端请求时，用于告诉服务端自己可以接受哪些数据格式。

### Content-Encoding
说明数据的压缩方法，表示服务器返回的数据使用了什么压缩格式。

### Accpet-Encoding
客户端在请求时用于说明自己可以接受哪些压缩方法。

## GET & POST
### 区别
GET 的语义是从服务器获取指定的资源。

GET请求的参数位置一般是写在URL中，URL规定只能支持ASCII，所以GET请求的参数只允许ASCII字符，且浏览器会对URL的大小有所限制（HTTP协议没有做限制）。

POST 的语义是根据请求负荷（报文body）对指定的资源做出处理。

具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。
### GET 和 POST 方法都是安全和幂等的吗？
安全：请求方法不会破坏服务器上的资源。

幂等：多次执行相同的操作，结果都是相同的。

根据RFC规范定义的语义来看：

GET 方法安全且幂等，因为它是【只读】操作，所以可以对 GET 请求的数据进行缓存，而且浏览器中的 GET 请求可以保存为书签。

POST 是【提交数据】，会修改服务器上的资源，因此不安全。且多次提交数据就会创建多个资源，因此不幂等。所以一般不会缓存 POST 请求也不能保存为书签。

但在实际开发中，可以用GET实现数据删改，这样的GET不安全幂等。也可以用POST只查询数据，这样的POST安全幂等。

GET 也可以带body，只是 RFC 规定的GET是用来获取资源的，所以不需要用到body。

URL的查询参数也并非GET独有，POST请求的URL中也可以带有参数。

# HTTP缓存
- 有强制缓存和协商缓存两种。一般当强制缓存miss时，才使用协商缓存
## 强制缓存
- 客户端缓存的有效期：`Cache-Control`，相对时间；`Expires`，绝对时间。

    Cache-Control 的优先级大于 Expires的优先级。

## 协商缓存
- 即与服务器交流缓存中的资源是否被修改，如果被修改则重新发送服务器中的资源；如果未被修改则继续使用缓存中的资源。
- 第一种头部：
    >响应头部中的`Last-Modified`：标示这个响应资源的最后修改时间。  

    > 请求头部中的`If-Modified-Since`：资源过期时将此值设为上一个响应中收到的Last-Modified对比现在的服务器`Last-Modified`和上一次的`Last-Modified`就可以判断网页是否改变
- 第二种头部：
    >响应头部中的`Etag`：唯一标识响应资源。

    >请求头部中的`If-None-Match`：发送请求时将此值设为之前的Etag值，与当前服务器中的Etag值对比即可。

Etag 的优先级高于 Last-Modified 的优先级。原因如下：

1. 在没有修改文件的情况下，Last-Modified 也可能会发生改动，会导致不必要的重新请求。

2. 有些文件可能是在秒级以内修改的，而If-Modified-Since的精度只有秒级，Etag能实现更高的精度。

3. 有些服务器不能精确获取文件的最后修改时间。

> 注意  
协商缓存都要配合强制缓存中的Cache-Control字段来使用。只有在miss强制缓存的情况下才能发起带有协商缓存字段的请求。

# HTTP特性
## HTTP/1.1 优点
1. 简单。基本的报文格式就是`header+body`，头部信息也是`key-value`简单文本的形式，易于理解。

2. 灵活和易于扩展。

3. 应用广泛和跨平台。

## HTTP/1.1 缺点
1. 无状态。无状态使得服务器不会记忆HTTP的状态，所以不用消耗资源来记录状态信息。但是由于服务器没有记忆能力，在处理有关联性的任务时非常麻烦。

    例如登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

    解决这个问题其中一种技术是【Cookie】技术。

    ![cookie1](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/14-cookie%E6%8A%80%E6%9C%AF.png)
    ![cookie2](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/14-cookie%E6%8A%80%E6%9C%AF.png)

2. 明文传输。
明文传输方便阅读，抓包时可以肉眼查看，为调试带来方便。但是这也意味着HTTP没有保密性，十分不安全。

## HTTP/1.1 性能
1. 长连接。HTTP/1.0 每发起一次请求，都要新建一次TCP连接，而且是串行请求。

    HTTP/1.1 默认使用长连接（Connection：Keep-Alive）。没有一方明确提出断开连接就一直保持TCP连接。

2. 管道网络传输。串行的请求模式必须等待前一个请求得到回应后，才能发出B请求。而管道网络传输可以一次发起多个请求，减少整体的响应时间。

    ![管道传输](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/17-%E7%AE%A1%E9%81%93%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93.png)

但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应。

如果服务端在处理 前一个 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。

所以，HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。

> 注意！！！  
HTTP/1.1 管道化技术不是默认开启，而且浏览器基本不支持，此项功能没有被使用。

3. 队头阻塞。当顺序发送的请求序列中的一个请求被阻塞了，在后面排队的所有请求都会被阻塞。

# HTTP与HTTPS
HTTP存在窃听风险、篡改风险、冒充风险。

HTTPS在HTTP与TCP层之间加入了`SSL/TLS`协议，实现了信息加密、校验机制、身份证书，从而解决了上述风险。

具体实现——

1. 混合加密。保证信息的机密性。

    在通信建立前采用【非对称加密】（公钥私钥）来交换会话密钥，后续使用【会话密钥】来加密明文数据。
--------------------

## 介绍一下非对称加密算法
流程的不同，意味着目的也不相同：

- 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；

- 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

---------------------
2. 摘要算法+数字签名。保证传输的内容不被篡改。

    ### 摘要算法
    A先用摘要算法（通常使用哈希函数实现）计算出内容的哈希值。这个哈希值是唯一的，且无法通过哈希值推导出内容。

    A将内容和哈希值一起发送给B，B对内容进行解密后再进行摘要算法运算，得出的结果如果和接收的哈希值一致，就说明内容没有被篡改。

    这样就能保证传输的【内容】的完整性，但是有可能【内容】和【哈希值】一起被替换，这就需要客户端有确认消息是否来自服务端的能力。

    ### 数字签名
    服务端通过私钥加密内容的【哈希值】，发送给客户端。

    我们使用服务端提供的公钥，如果可以解密出一个哈希值A，而这个哈希值恰巧与【内容】的哈希值B相同，则在这对公私钥不被替换的情况下，就能证明内容来自于正确的服务端。

3. 数字证书。

    有了数字签名，我们还是无法确认消息来自正确的服务端，因为第三方可能会伪造用于解密数字签名的公钥。

    我们需要验证对方的身份。

    拿请假的例子，虽然你爸爸持有私钥，老师通过是否能用公钥解密来确认这个请假条是不是来源你父亲的。

    但是我们还可以自己伪造出一对公私钥啊！

    你找了个夜晚，偷偷把老师桌面上和你爸爸配对的公钥，换成了你的公钥，那么下次你在请假的时候，你继续模仿你爸爸的字迹写了个请假条，然后用你的私钥做个了「数字签名」。

    但是老师并不知道自己的公钥被你替换过了，所以他还是按照往常一样用公钥解密，由于这个公钥和你的私钥是配对的，老师当然能用这个被替换的公钥解密出来，并且确认了内容的完整性，于是老师就会以为是你父亲写的请假条，又允许你请假了。

    既然伪造公私钥那么随意，所以你爸把他的公钥注册到警察局，警察局用他们自己的私钥对你父亲的公钥做了个数字签名，然后把你爸爸的「个人信息 + 公钥 + 数字签名」打包成一个数字证书，也就是说这个数字证书包含你爸爸的公钥。

    老师拿到了数字证书后，首先会去警察局验证这个数字证书是否合法，因为数字证书里有警察局的数字签名，警察局要验证证书合法性的时候，用自己的公钥解密，如果能解密成功，就说明这个数字证书是在警察局注册过的，就认为该数字证书是合法的，然后就会把数字证书里头的公钥（你爸爸的）给到老师。

    由于通过警察局验证了数字证书是合法的，那么就能证明这个公钥就是你父亲的，于是老师就可以安心的用这个公钥解密出请假条，如果能解密出，就证明是你爸爸写的请假条。

    正是通过了一个权威的机构来证明你爸爸的身份，所以你的伪造公私钥这个小伎俩就没用了。

    在计算机里，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

    ![加密完整流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

## HTTPS 是如何建立连接的
![https](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

上图基于 RSA 握手算法。但是这种方式存在【前向安全】的问题：如果服务端的私钥泄露，过去被截获的所有 TLS 密文都会被破解。

而 ECDHE 密钥协商算法可以解决这个问题，这也是大多数网站所使用的。

## 证书信任链
![证书信任链](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E9%93%BE.png)

我们接收到服务器证书后，因为我们没办法确认证书的真实性，所以不能立即使用证书中提供的服务器公钥来进行传输内容的加密，而是要先向它的上级证书签发机构申请验证证书的真实性。

但是上级CA可能是中间证书签发机构或其他不能被浏览器信任的情况，所以我们要再向上级请求，直到找到根证书为止。

随后我们使用已经在系统中内置的根证书中的公钥，去验证中间证书的数字签名是否真实。如果真实，则说明中间证书确实是由根证书管理机构颁发的，就可以使用中间证书中的公钥，来验证服务器数字签名的真实性。如果真实，则说明服务器证书确实是由值得信赖的中间证书管理机构颁发的，服务器是真实且安全的，那么就可以使用服务器证书中的公钥，加密信息，发送给服务器。

为什么要搞证书链这么麻烦的流程呢？

1. 安全性。根证书私钥的保密性至关重要，如果此私钥泄露，整个信任链都会有问题。所以我们将根证书离线保存在本地并仅签署较少的中间CA证书，可以降低私钥泄露或被攻击的风险。

2. 灵活性和可替代性。如果中间层级的证书发生故障、过期或需要撤销时，可以相对容易地替换或更新中间层级的证书，而无需重新签署根证书，减少对根证书的操作和风险。同时，中间层级CA也可以更灵活更频繁地进行证书的颁发和管理。

## HTTPS 的应用数据是如何保证完整性的？
TLS 在实现上分为【握手协议】和【记录协议】两层：

- 握手协议就是TLS四次握手的过程，负责协商加密算法和生成对称密钥。

- 记录协议负责保护应用程序数据并验证其完整性和来源，所以对HTTP数据加密是使用记录协议。

![记录协议](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E8%AE%B0%E5%BD%95%E5%8D%8F%E8%AE%AE.png)

步骤：

1. 对HTTP消息分割成不同片段再进行压缩。

2. 对压缩的片段加上消息认证码（MAC值，对片段进行哈希而生成），类似摘要算法，确保消息的完整性。同时为了防止重放攻击，计算消息认证码时，还加上了片段的编码。

3. 对压缩片段使用对称密钥进行加密，再加上由数据类型、版本号、压缩后的长度组成的报头，组成最终的报文。

## HTTPS 一定安全可靠吗？
是的。

除非你主动信任不可靠的证书或者电脑被病毒植入了不可靠的根证书。但这不是HTTP的锅。

# HTTP 演变
## HTTP/1.1还存在哪些缺点
- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分；

- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；

- 没有请求优先级控制；

- 请求只能从客户端开始，服务器只能被动响应。

## HTTP/2 做了什么优化
1. 头部压缩。

    如果你同时发出多个请求，它们的头部是一样/相似的，协议会帮你消除重复的部分。

    这就是 `HPACK` 算法：在客户端和服务端同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

    比如状态码 200 ，在 HTTP/1.1 是用 '2''0''0' 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节。 HTTP/2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP/1.1 节省了 2 个字节。这是因为客户端和服务端都维护了头信息表中的【静态编码表】，状态码200就在其中，所以我们只需要发送一个字节的索引号即可表示“状态码200”。

    > 在表中未确定的头部值，可能会经过哈夫曼编码的压缩。
    #### 静态表编码
    静态表只包含了61种高频出现在头部的字符串。

    #### 动态表编码
    index从62起步。第一次发送时头部中的字段数据新建至动态表，下一次就只发送索引号即可。

    动态表生效前提：必须在同一个连接上，重复传输完全相同的HTTP头部。

    动态表越大，所占内存也就越大，性能也会受到影响，所以动态表会有一个设定的数量上限。

2. 二进制格式。

    HTTP/1.1是纯文本形式的报文，而HTTP/2采用二进制格式，头信息和数据体都是二进制，统称为【帧】：头信息帧和数据帧。

    不过HTTP/2还有一些其他功能的帧，如优先级帧、设置帧等等。

    对计算机解析报文非常友好，增加了数据传输的效率。

3. 并发传输。多个Stream复用一条TCP连接，达到并发的效果。

    ![Stream](https://cdn.xiaolincoding.com//picgo/image-20240105143224839.png)

    - 一个TCP连接包含一个或多个Stream。

    - Stream里可以包含一条或多条Message，Message对应HTTP/1.1种的请求/响应。

    - Message里包含一条或者多个Frame，Frame是HTTP/2的最小单位。

    因此，我们可以得出个结论：多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。

    虽然消息概念在HTTP/2的语义上仍然存在，但在传输层面上，HTTP/2是以帧为单位进行数据传输和处理的。帧的使用允许多个请求和响应在同一个连接上并行传输，以提高传输效率和性能。

    因此，HTTP/2的传输单位是帧，而不是整个消息。

    不同Stream的帧可以乱序发送（因此可以并发不同的Stream），因为每个帧头部会携带Stream ID 信息，接收端可以据此有序组装成HTTP消息；而同一Stream内部的帧必须是严格有序的，需要根据这个顺序来组装成消息。

    同一个TCP连接中的Stream ID不能复用，Stream ID耗尽时，需要关闭TCP连接。

    HTTP/2 通过 Stream 实现的并发，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多，因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过 TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的。

4. 服务端推送。

    服务端现在可以主动推送资源给客户端了。客户端建立的Stream必须是奇数号，服务端必须是偶数号。

    ![有无服务器推送的区别](https://cdn.xiaolincoding.com//picgo/image-20240105143315109.png)

    可以看出有很明显的性能差距。

    当客户端向服务器请求资源时，服务器除了返回请求的资源外，还会通过`PUSH_PROMISE`帧传输HTTP头部，告知客户端接下来在哪个Stream中发送包体。

    ![推送过程](https://cdn.xiaolincoding.com//picgo/image-20240105143338707.png)

    注意，Stream1和Stream2是可以并发的。

5. 可以设置Stream的优先级。

## HTTP/2 缺点
1. 响应的队头阻塞。
    HTTP/1.1管道化解决了【请求】的队头阻塞，但没有解决【响应】的队头阻塞。

    HTTP/2 Stream并行传输解决了【响应】的队头阻塞，但是没有解决TCP的队头阻塞。

    由于TCP必须保证收到的字节数据是完整且连续的，内核才会将缓冲区中里的数据返回给HTTP应用，所以当【前一个字节数据】没有到达时，后面到的所有数据就都被阻塞了，及时后面的是完整的消息，也无法读取。这就是HTTP/2队头阻塞。

2. TCP 与 TLS 的握手时延迟。需要经过TCP三次握手和TLS四次握手（TLS 1.2），需要3个RTT的时延才能发出请求。

    另外，TCP拥塞控制也会在开始阶段减速连接。

3. 网络迁移需要重新连接。

    一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WiFi。

## HTTP/3 做了哪些优化
HTTP/3使用UDP协议+基于UDP的QUIC协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。

1. 无队头阻塞。

    HTTP/3基于UDP，UDP不关心数据包的顺序和是否丢失。

    HTTP/3使用QUIC协议确保数据包的可靠性，每个数据包都有一个唯一标识。当某个流中的一个数据包丢失，这个流被阻塞，但其他流不会受到影响。

2. 更快的建立连接。

    HTTP/3的QUIC协议内置TLS 1.3，且没有TCP 3次握手，因此只需1个RTT就可以同时完成连接与密钥协商。甚至在第二次连接时，应用数据包可以和QUIC握手信息一起发送，达到0-RRT。

3. 连接迁移。

    QUIC协议没有像TCP那样使用四元组绑定连接，而是通过【连接ID】来标记通信的两个端点。当网络发生变化时，只要仍保留有上下文信息（比如连接 ID、TLS密钥）等，就可以快速复用原连接。

4. 更新头部压缩算法。

    将HPACK升级为QPACK，静态表扩张到91项。

    动态表具有时序性，如果首次出现的请求发生了丢包，后续的请求就无法按照索引号解码出头部，因为对方还没建立动态表。

    QPACK建立了两个单向流QPACK Encoder Stream和QPACK Decoder Stream。前者用于发送动态表建立信息；后者用于通知对方“已建立好动态表，可以使用索引号来进行通信”。当编码方收到确认信息后，才使用动态表编码HTTP头部。

# SSL/TLS
## TLS 1.2 第一次连接 with RSA密钥协商算法
### TLS 第一次握手
客户端首先发送【Client Hello】消息，其中有客户端使用的TLS版本号、支持的密码套件列表，以及生成的【随机数】。

### TLS 第二次握手
服务端回应【Client Hello】消息，确认TLS版本号是否支持，选择密码套件，生成【随机数】，发送给客户端。

服务端为证明自己的身份，发送【Server Certificate】给客户端，这个消息内含有服务端的数字证书。

随后发送【Server Hello Done】消息，告诉客户端本次握手需要传给你的消息已经传输完毕。

### TLS 第三次握手
客户端验证完证书后使用证书中的公钥加密新生成的随机数【pre-master】通过【Client Key Exchange】消息传给服务端。

服务端收到后用 RSA 私钥解密，得到pre-master，随后三个随机数计算出【会话密钥】。

客户端生成完【会话密钥】后，客户端发一个【Change Cipher Spec】消息告诉服务端开始使用加密方式发送消息。

随后再发送一个【Encrypted Handshake Message（Finishd）】消息，把之前所有发送的数据做个摘要，用会话密钥加密，让服务器做验证，验证加密通信【是否可用】和【之前握手信息是否有被中途篡改过】。

「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。

### TLS 第四次握手
服务器也是同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

### RAS算法缺陷
不支持前向保密。一旦服务端的私钥泄露了，那么就能解开以前截获的使用公钥加密的pre-master密钥信息。于是就可以计算出会话密钥。所有被截获的数据都会被破解。

## TLS 1.2 第一次连接 with ECDHE密钥协商算法
### TLS False Start
使用了 ECDHE，在 TLS 第三次握手后，客户端就已经发送了加密的 HTTP 数据，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。

所以，ECDHE 相比 RSA 握手过程省去了一个消息往返的时间，这个有点「抢跑」的意思，它被称为是「TLS False Start」，跟「TCP Fast Open」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。

### TLS 第一次握手
【Client Hello】，有客户端使用的TLS版本号，支持的密码套件和生成的随机数（Client Random）。

### TLS 第二次握手
【Server Hello】，有服务端确认的版本号、密码套件，生成随机数（Client Random）。

【Certificate】，将证书发送。

> 注意  
ECDHE增加了下面这步  

【Server Key Exchange】，选择椭圆曲线（选好椭圆曲线也相当于定好基点G）；生成随机数作为服务端椭圆曲线的私钥，保存在本地；根据G和私钥计算出服务端椭圆曲线的公钥，公开给客户端。为保证椭圆曲线不被篡改，服务端会用RSA签名算法给其签名。

【Server Hello Done】，服务端表明这就是我所需要提供的消息，本次握手结束。

自此，服务端和客户端共享了Client Random、Server Random、使用的椭圆曲线、椭圆曲线基点G、服务端椭圆曲线的公钥。

### TLS 第三次握手
【Client Key Exchange】，生成随机数作为客户端椭圆曲线的私钥，生成公钥，发送给服务端。

此时双方都有对方的公钥、自己的私钥、椭圆曲线基点G，于是就可以计算出点(x,y)，x值双方相同，使用x+Client Random+Server Random三个材料生成【会话密钥】。

【Change Cipher Spec】，告诉服务端后续用会话密钥通信。

【Encrypted Handshake Message】，把之前的数据做摘要让服务器验证【加密通信是否可用】和【之前握手信息是否有被中途篡改过】。

### TLS 第四次握手
服务器也是同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

## ECDHE 比 RSA 的优势
ECDHE 有前向保密的能力。

有人可能会说，那RSA每次通信都把自己的公私钥对换一下不就行了吗？但是公钥是储存在数字证书中的，每次更换公私钥，就意味着要重新颁发证书，非常麻烦。

## TLS 1.3
TLS 1.3 只支持ECDHE算法。

![1.2 vs 1.3](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls1.2and1.3.png)

客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。

服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。

## 会话复用
TLS 握手的目的就是为了协商出会话密钥，也就是对称加密密钥，那我们如果我们把首次 TLS 握手协商的对称加密密钥缓存起来，待下次需要建立 HTTPS 连接时，直接「复用」这个密钥，不就减少 TLS 握手的性能损耗了吗？

这种方式就是会话复用（TLS session resumption），会话复用分两种：

- 第一种叫 Session ID；
- 第二种叫 Session Ticket；

但是会话复用不仅难以防止重放攻击，而且不具备前向安全，所以应当对会话密钥设定一个合理的过期时间，或者只对安全的HTTP请求如GET/HEAD使用会话重用。
### Session ID
客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识，Session ID 和会话密钥相当于 key-value 的关系。

客户端再次连接时，在hello消息里带上Session ID，就可以恢复与服务器的TLS连接。

但是它有两个缺点：

- 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，服务器的内存压力也会越大。
- 现在网站服务一般是由多台服务器通过负载均衡提供服务的，客户端再次连接不一定会命中上次访问过的服务器，于是还要走完整的 TLS 握手过程；

### Session Ticket
为了解决 Session ID 的问题，就出现了 Session Ticket，服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端，类似于 HTTP 的 Cookie。

客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。

客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。

对于集群服务器的话，要确保每台服务器加密 「会话密钥」的密钥是一致的，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。

Session ID 和 Session Ticket 都不具备前向安全性，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。

同时应对重放攻击也很困难，这里简单介绍下重放攻击工作的原理。

![重放攻击](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB.png)

假设 Alice 想向 Bob 证明自己的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全力提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。

交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后一个会话中读取的 Alice 的密码（或哈希），从而授予 Eve 访问权限。

重放攻击的危险之处在于，如果中间人截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报文，而一般 POST 请求会改变数据库的数据，中间人就可以利用此截获的报文，不断向服务器发送该报文，这样就会导致数据库的数据被中间人改变了，而客户是不知情的。

避免重放攻击的方式就是需要对会话密钥设定一个合理的过期时间。

### Pre-shared Key
前面的 Session ID 和 Session Ticket 方式都需要在 1 RTT 才能恢复会话。

而 TLS1.3 更为牛逼，对于重连 TLS1.3 只需要 0 RTT，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 Pre-shared Key。

同样的，Pre-shared Key 也有重放攻击的危险。

如上图，假设中间人通过某种方式，截获了客户端使用会话重用技术的 POST 请求，通常 POST 请求是会改变数据库的数据，然后中间人就可以把截获的这个报文发送给服务器，服务器收到后，也认为是合法的，于是就恢复会话，致使数据库的数据又被更改，但是此时用户是不知情的。

所以，应对重放攻击可以给会话密钥设定一个合理的过期时间，以及只针对安全的 HTTP 请求如 GET/HEAD 使用会话重用。

# TCP 基础
TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。

- 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；

- 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

- 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。
## TCP头格式
![tcp头格式](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png)

`序列号`：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。

`确认应答号`：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。

`控制位`：

- ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。
- RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。
- SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。

## 如何唯一确定一个TCP连接
使用由【源地址】、【目的地址】、【源端口】、【目的端口】构成的四元组。

由于TCP是由四元组确定一个连接，那么当四个元素都相同时，我们就无法将第二个TCP连接绑定到一样的端口上。

# UDP
UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。

UDP协议本身并不对应用层数据进行分段或重新组装，因此，UDP数据报的边界取决于应用程序发送数据的方式。应用程序可以根据自身的需求将数据分割为适当大小的块，并将每个块封装为一个UDP数据报。这意味着一个UDP数据报可以包含完整的应用层数据块，也可以跨越多个应用层数据块。

头部格式如下：

![udp头格式](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230439961.png)

TCP 和 UDP 区别：

1. 连接

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。
2. 服务对象

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信
3. 可靠性

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：如何基于 UDP 协议实现可靠传输？(opens new window)
4. 拥塞控制、流量控制

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. 首部开销

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。
6. 传输方式

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。
7. 分片不同

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

> 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？

原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。

> 为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？

先说说 TCP 是如何计算负载数据长度：

![tcp计算长度](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230445811.png)

其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。

> TCP 和 UDP 可以使用同一个端口吗？

可以。负责处理tcp和udp报文的模块在主机中是独立的两个部分，互不干扰。

![共用端口](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/port/tcp%E5%92%8Cudp%E6%A8%A1%E5%9D%97.jpeg)

# TCP 建立连接
## 三次握手过程
![三次握手](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png)

TCP 在第三次握手时就可以携带数据了，前两次握手不可以携带数据。但是在第三次握手时无法进行TLS连接。

    在传统的TCP连接中，第三次握手是用于确认双方都可以建立可靠的通信连接。然而，TLS（Transport Layer Security）是一种安全协议，用于在应用层之上为数据传输提供加密和认证。

    在建立TLS连接时，通常会在TCP连接建立之后进行TLS握手过程，而不是直接在TCP的第三次握手时建立TLS连接。TLS握手涉及协商加密算法、证书验证和密钥交换等步骤，以确保通信的安全性。

    TLS握手通常在TCP连接建立后的应用层发生，即在HTTP、SMTP、FTP等协议的应用层之上。一旦TCP连接建立并且应用层选择使用TLS进行加密，客户端和服务器将进行TLS握手来协商安全参数、验证身份、交换密钥等。这种方式确保了在应用层之上建立安全的通信通道。

## 为什么不是两次或四次握手
1. 避免历史连接

    三次握手避免历史连接图示：

    ![三次握手避免历史连接图示](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230525514.png)

    如果在服务端在收到客户端的RST报文之前接收到了新的SYN，由于这个报文的seq不是自己期望得到的，因此会发送Challenge Ack报文（即重发上一次的SYN+ACK）报文。随后客户端收到该报文，发现其中的序列号seq不是自己期望得到的，于是发出RST报文终止连接。

    两次握手会导致客户端发送的SYN报文一经服务端接收不经过客户端确认就建立连接，无法阻止历史连接的建立。直到客户端发现服务器回应的SYN+ACK报文不是它想要的，才发送RST报文断开连接；并且在接收到RST报文前，服务器可能会白白发送数据，浪费服务器资源。

    > 如果第三次握手时ACK报文丢失了，那是不是这次随ACK报文一起发送的数据报文就浪费了？

    NO，因为数据报文中也含有序列号seq和确认序列号ack，因此收到数据就相当于收到了ACK报文。
2. 同步双方初始序列号

    两次握手只能确认服务器收到了客户端发送的序列号，但无法确认客户端收到了服务器的序列号。不能保证双方的初始序列号能被可靠的同步。

    服务端第二次握手可以将SYN报文和ACK报文分别发送，看作四次握手，但是没必要。
3. 避免资源浪费

    两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 SYN 报文，而造成重复分配资源。

## 为什么每次建立TCP连接时，初始化序列号的要求都不一样呢？
主要原因有两个方面：

- 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

接下来，详细说说第一点。

![如果初始化序列号一样？](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E7%9B%B8%E5%90%8C.png)

如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。

RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。

M是一个计时器，这个计时器每隔 4 微秒加1。
F 是一个 Hash 算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。

可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。且序列号同一个四元组的不同TCP连接中，初始化序列号随时间不断递增。

![初始化序列号不一样](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E4%B8%8D%E7%9B%B8%E5%90%8C.png)

所以，每次初始化序列号不一样很大程度上能够避免历史报文被下一个相同四元组的连接接收。

但是当我们的序列号用完了，会产生回绕，回到初始值再继续递增。这时就无法根据序列号来判断新老数据。

因此，我们在TCP头部中加入【时间戳】选项，不仅能防止序列号回绕，还帮助我们精确计算RTT。

![timestamp](https://cdn.xiaolincoding.com//mysql/other/1d497c38621ebc44ee3d8763fd03da67.png)

32 位的序列号在时刻 D 和 E 之间回绕。假设在时刻B有一个报文丢失并被重传，又假设这个报文段在网络上绕了远路并在时刻 F 重新出现。如果 TCP 无法识别这个绕回的报文，那么数据完整性就会遭到破坏。

使用时间戳选项能够有效的防止上述问题，如果丢失的报文会在时刻 F 重新出现，由于它的时间戳为 2，小于最近的有效时间戳（5 或 6），因此防回绕序列号算法（PAWS）会将其丢弃。

防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包。

时间戳的大小是 32 bit，所以理论上也是有回绕的可能性的。

但是当时间戳回绕，序列号还刚好和服务端接收窗口重合的概率太小了，可以忽略这种情况。

当然，如果TCP经过正常的4次挥手断开连接，我们是可以保证历史连接中的数据已经在网络中消失了的，也就用不到序列号和时间戳来防范历史数据错误接收的问题了。

## 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？
如果TCP不分片，一个TCP消息的大小超过IP数据报所能载荷的大小，IP层就会私自给一份TCP消息切割成几分IP分片。

一旦当接收到的IP分片不完整时，就无法组装成一份完整的TCP报文，也就无法向上交付给TCP传输层。而IP层又没有TCP层的超时重传机制，一个IP分片丢失了就彻底没了，这样就导致整个TCP报文都得重传。

因此，TCP限定TCP报文的最大数据长度不超过MSS值，主动对TCP报文进行分片。同时分片后的报文自己就相当于一条独立的TCP报文，当然由它形成的IP包的长度也就不会大于MTU值（IP包的最大长度）。于是，一条IP分片就对应一条TCP分片（报文）。即使一个IP分片丢失，也不影响其他TCP分片的交付。

这样TCP在进行重传时就以MSS为单位了，而不用重传所有的分片。

## 第一次握手丢失了会发生什么？
客户端SYN报文丢失，收不到服务端的回应，会触发超时重传。当达到重传次数上限并且等待一段时间后仍没有回应，就会主动断开连接。
## 第二次握手丢失了会发生什么？
服务端SYN+ACK报文丢失，客户端收不到服务端的回应，服务端也收不到客户端的第三次握手响应。于是客户端重传SYN报文，服务端重传SYN+ACK报文。达到重传次数上限并等待一段时间后主动关闭连接。
## 第三次握手丢失了会发生什么？
无论是握手还是挥手，ACK报文都不会重传。第三次丢失，服务器收不到响应，会重传SYN+ACK报文。达到重传次数上限并等待一段时间后主动关闭连接。

## 什么是SYN攻击？
客户端发送SYN报文后，服务器会进入SYN-RCVD状态，但是服务器发送的SYN+ACK报文得不到应答就会占据【服务端的半连接】队列，使得服务器不能为正常用户提供服务。

# TCP 断开连接
## 四次挥手过程
![四次挥手](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230614791.png)

`主动关闭连接的，才有 TIME_WAIT 状态。`

## 为什么需要四次挥手？
第二次挥手后，服务端中可能还有需要传输的数据，因此需要等数据传输完毕后，再由服务端主动进行第三次挥手。

但是在特殊情况下可以变为三次挥手。

## 三次挥手：将第二、三次挥手的ACK和FIN合在一起发送
当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。
### TCP延迟确认
因为发送没有携带数据的ACK的网络效率很低（没有数据，却需要发送庞大的TCP头），所以需要使用延迟确认：

- 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
- 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
- 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

TCP延迟确认机制是默认开启的。

## 第一次挥手丢失了会发生什么？
客户端FIN报文丢失超时重传，超过最大重传次数等待一段时间后就断开连接。
## 第二次挥手丢失了会发生什么？
服务端ACK报文丢失，ACK不会主动重传。客户端未收到第一次挥手的响应，重传FIN，服务器继续发送ACK报文，若继续丢失，则继续重传FIN。重传次数达到上限后经过一定时间，客户端主动断开连接。
## 第三次挥手丢失了会发生什么？
服务端FIN报文丢失，迟迟收不到客户端的第四次挥手，则重传FIN。达到重传次数上限后经过一段时间服务器主动断开连接。

如果客户端使用close函数发起断开TCP请求，则FIN_WAIT_2状态会默认等待60s。60s内收不到第三次挥手则客户端主动断开连接。

如果使用shutdown函数关闭连接，且只关闭发送数据的方向，客户端则会死等在FIN_WAIT_2状态，直到收到服务端的FIN报文。
## 第四次挥手丢失了会发生什么？
ACK报文不会重传，于是服务端重发FIN报文。重传次数达到上限后经过一段时间服务端主动关闭连接。

客户端在收到第三次挥手后会进入TIME_WAIT状态，倒计时2MSL后再关闭连接。如果这期间再次收到第三次挥手报文，则重置计时器。

![第四次挥手](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1drawio.drawio.png)

## 为什么 TIME_WAIT 等待的时间是 2MSL？
MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。

TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。

比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。

可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。

## 为什么需要 TIME_WAIT 状态？
主动发起关闭连接的一方才有TIME_WAIT状态。

原因如下：
1. 防止历史连接中的数据被后面相同四元组的错误连接的接收

    TIME_WAIT 状态，状态会持续 2MSL 时长，这个时间足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

2. 保证【被动关闭连接】的一方能够被正确的关闭

    TIME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。

    如果TIME-WAIT过短或没有，那么当被动关闭一方的FIN超时重传之后，主动关闭一方已经处于Close状态，无法重发ACK报文，只能发送RST报文来关闭被动一方的连接。而被动关闭的一方会将RST解释为一个错误，这对于一个可靠的协议来说不是一个优雅的终止方式。

## TIME_WAIT 过多有什么危害
过多的 TIME-WAIT 状态主要的危害有两种：

- 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用端口资源，端口资源也是有限的。

如果客户端（为主动发起关闭连接方）的TIME_WAIT状态过多，占满了所有端口资源，就无法再跟【目的IP+目的PORT】都一样的服务端发起连接了。但是被使用的端口，还是可以继续对另一个服务端发起连接。

如果服务端（为主动发起关闭连接方）的TIME_WAIT状态过多，并不会导致端口资源受限，因为服务端只监听一个端口。而且由于一个四元组唯一确定一个TCP连接，因此理论上服务端可以建立很多连接。但TCP连接过多会占用系统资源。

如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。

## 服务器出现大量 TIME_WAIT 状态的原因有哪些？
首先要知道 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。

问题来了，什么场景下服务端会主动断开连接呢？

- 第一个场景：HTTP 没有使用长连接
- 第二个场景：HTTP 长连接超时
- 第三个场景：HTTP 长连接的请求数量达到上限

第一个场景下，无论是哪一方设置不使用长连接，在大多数web服务的实现中，都是由服务器主动断开TCP连接。

    针对这个场景下，解决的方式也很简单，让客户端和服务端都开启 HTTP Keep-Alive 机制。

第二个场景下，如果客户端在一段时间内没有发送请求，服务器就会主动关闭连接。

    可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。

第三个场景下，如果这个 HTTP 长连接上已经接收并处理的客户端请求的数量达到web服务器设定上限，服务器就会主动关闭这个TTP长连接。

    keepalive_requests 参数的默认值是 100 ，意味着每个 HTTP 长连接最多只能跑 100 次请求，这个参数往往被大多数人忽略，因为当 QPS (每秒请求数) 不是很高时，默认值 100 凑合够用。

    对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态。

    针对这个场景下，解决的方式也很简单，调大 nginx 的 keepalive_requests 参数就行。

# TCP Fast Open ｜｜ TCP 能和 TLS 同时握手吗？
客户端第一次与服务端建立TCP连接时，前两次握手不可以携带数据，第三次握手可以携带数据，但是第三次握手不能进行TLS连接。

如果客户端和服务端同时开启了 TCP Fast Open 功能，第一次TCP连接就是这样的：

![fast open first](https://cdn.xiaolincoding.com//mysql/other/7cb0bd3cde30493fec9562cbdb549f83.png)

- 客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；
- 支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 报文中的 Fast Open 选项以发回客户端；
- 客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。

后续建立连接时，客户端就可以在第一次握手时携带应用数据，从而达到绕过三次握手发送数据的效果：

![后续](https://cdn.xiaolincoding.com//mysql/other/fc452688b9351e0cabf60212dde3f21e.png)

我详细介绍下这个过程：

- 客户端发送 SYN 报文，该报文可以携带「应用数据」以及此前记录的 Cookie；

- 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「应用数据」递送给对应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「应用数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；
- 如果服务器接受了 SYN 报文中的「应用数据」，服务器可在握手完成之前发送「响应数据」，这就减少了握手带来的 1 个 RTT 的时间消耗；
- 客户端将发送 ACK 确认服务器发回的 SYN 以及「应用数据」，但如果客户端在初始的 SYN 报文中发送的「应用数据」没有被确认，则客户端将重新发送「应用数据」；
- 此后的 TCP 连接的数据传输过程和非 TCP Fast Open 的正常情况一致。

## TCP Fast Open + TLSv1.3 
客户端和服务端同时支持 TCP Fast Open 功能的情况下，在第二次以后到通信过程中，客户端可以绕过三次握手直接发送数据，而且服务端也不需要等收到第三次握手后才发送数据。

    因此如果「TCP Fast Open + TLSv1.3」情况下，在第二次以后的通信过程中，TLS 和 TCP 的握手过程是可以同时进行的。

如果基于 TCP Fast Open 场景下的 TLSv1.3 0-RTT 会话恢复过程，不仅 TLS 和 TCP 的握手过程是可以同时进行的，而且 HTTP 请求也可以在这期间内一同完成。